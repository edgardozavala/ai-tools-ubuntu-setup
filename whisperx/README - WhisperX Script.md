# üéôÔ∏è WhisperX - Script Completo de Transcripci√≥n

Script Python completo para transcripci√≥n de audio con WhisperX, similar a [Replicate's WhisperX](https://replicate.com/victor-upmeet/whisperx).

## ‚ú® Caracter√≠sticas

- ‚úÖ **Transcripci√≥n r√°pida** con aceleraci√≥n CUDA (70x tiempo real)
- ‚úÖ **Timestamps precisos** a nivel de palabra con alineaci√≥n forzada
- ‚úÖ **Diarizaci√≥n de hablantes** (identificaci√≥n de qui√©n habla)
- ‚úÖ **M√∫ltiples formatos de salida**: JSON, TXT, SRT, VTT
- ‚úÖ **Detecci√≥n autom√°tica de idioma** o especificaci√≥n manual
- ‚úÖ **Traducci√≥n a ingl√©s** opcional
- ‚úÖ **Gesti√≥n eficiente de memoria** GPU

## üìã Requisitos

```bash
# Aseg√∫rate de tener WhisperX instalado
source ~/whisperx_env/bin/activate

# Si no lo tienes, sigue la gu√≠a de instalaci√≥n:
# https://github.com/edgardozavala/ai-tools-ubuntu-setup/blob/main/whisperx/INSTALACION_WHISPERX.md
```

## üöÄ Uso R√°pido

### Transcripci√≥n b√°sica

```bash
python whisperx_script.py audio.mp3
```

**Resultado:**
- `output/audio.json` - Transcripci√≥n completa con timestamps
- `output/audio.txt` - Solo texto
- `output/audio.srt` - Subt√≠tulos formato SRT
- `output/audio.vtt` - Subt√≠tulos formato WebVTT

### Con idioma espec√≠fico (m√°s r√°pido)

```bash
python whisperx_script.py audio.mp3 --language es
```

### Con diarizaci√≥n de hablantes

```bash
# Requiere token de Hugging Face
# Obt√©n uno en: https://huggingface.co/settings/tokens
# Acepta el modelo: https://huggingface.co/pyannote/speaker-diarization-3.1

python whisperx_script.py audio.mp3 --diarize --hf-token YOUR_HF_TOKEN
```

**Salida con hablantes:**
```
[SPEAKER_00] Buenos d√≠as, ¬øc√≥mo est√°s?
[SPEAKER_01] Muy bien, gracias por preguntar.
[SPEAKER_00] Me alegro mucho de escucharlo.
```

## üìñ Ejemplos Avanzados

### 1. Podcast o entrevista con m√∫ltiples hablantes

```bash
python whisperx_script.py podcast.mp3 \
  --language es \
  --diarize \
  --hf-token YOUR_TOKEN \
  --min-speakers 2 \
  --max-speakers 4
```

### 2. Video de YouTube (usando audio extra√≠do)

```bash
# Primero extrae el audio con ffmpeg o yt-dlp
yt-dlp -x --audio-format mp3 "URL_DEL_VIDEO" -o video.mp3

# Luego transcribe
python whisperx_script.py video.mp3 --language es
```

### 3. Traducir audio al ingl√©s

```bash
python whisperx_script.py audio_espanol.mp3 --task translate
```

### 4. Modelo m√°s r√°pido (para pruebas)

```bash
# Modelo "base" es ~5x m√°s r√°pido pero menos preciso
python whisperx_script.py audio.mp3 --model base
```

### 5. Solo JSON (para procesamiento posterior)

```bash
python whisperx_script.py audio.mp3 --output-format json
```

### 6. Procesamiento en CPU (sin GPU)

```bash
python whisperx_script.py audio.mp3 --device cpu --compute-type float32
```

## ‚öôÔ∏è Par√°metros Completos

```
Uso: python whisperx_script.py [OPCIONES] AUDIO_FILE

Argumentos posicionales:
  audio                 Archivo de audio a transcribir

Opciones generales:
  -o, --output-dir      Directorio de salida (default: ./output)
  -m, --model           Modelo: tiny, base, small, medium, large-v2, large-v3
  -l, --language        C√≥digo de idioma: es, en, fr, de, it, pt, ja, zh, etc.
  -t, --task            transcribe o translate (a ingl√©s)
  -b, --batch-size      Tama√±o de lote (default: 16, reducir si hay poco VRAM)
  
Opciones de hardware:
  --device              cuda o cpu
  --compute-type        float16, int8, float32
  
Opciones de alineaci√≥n:
  --no-align            Deshabilitar alineaci√≥n de timestamps
  
Opciones de diarizaci√≥n:
  --diarize             Activar identificaci√≥n de hablantes
  --hf-token            Token de Hugging Face (requerido para diarizaci√≥n)
  --min-speakers        N√∫mero m√≠nimo de hablantes
  --max-speakers        N√∫mero m√°ximo de hablantes
  
Opciones de salida:
  --output-format       all, json, txt, srt, vtt
  -q, --quiet           Modo silencioso
```

## üìä Modelos Disponibles

| Modelo | Par√°metros | VRAM | Velocidad | Precisi√≥n | Uso Recomendado |
|--------|-----------|------|-----------|-----------|-----------------|
| `tiny` | 39M | ~1GB | 32x | ‚≠ê‚≠ê | Pruebas r√°pidas |
| `base` | 74M | ~1GB | 16x | ‚≠ê‚≠ê‚≠ê | Transcripci√≥n r√°pida |
| `small` | 244M | ~2GB | 6x | ‚≠ê‚≠ê‚≠ê‚≠ê | Balance calidad/velocidad |
| `medium` | 769M | ~5GB | 2x | ‚≠ê‚≠ê‚≠ê‚≠ê | Alta calidad |
| `large-v2` | 1550M | ~10GB | 1x | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | M√°xima precisi√≥n |
| `large-v3` | 1550M | ~10GB | 1x | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | √öltima versi√≥n (recomendado) |

## üåç Idiomas Soportados

**Con alineaci√≥n completa:**
- `es` - Espa√±ol
- `en` - Ingl√©s
- `fr` - Franc√©s
- `de` - Alem√°n
- `it` - Italiano
- `pt` - Portugu√©s
- `ja` - Japon√©s
- `zh` - Chino
- `nl` - Holand√©s
- [Y m√°s...](https://github.com/m-bain/whisperX#supported-languages)

**Otros idiomas:** Funcionan pero sin alineaci√≥n de palabras (timestamps menos precisos)

## üìÅ Formatos de Salida

### JSON (completo)
```json
{
  "segments": [
    {
      "start": 0.5,
      "end": 3.2,
      "text": " Hola, ¬øc√≥mo est√°s?",
      "words": [
        {"word": "Hola", "start": 0.5, "end": 0.9},
        {"word": "c√≥mo", "start": 1.2, "end": 1.5},
        {"word": "est√°s", "start": 1.6, "end": 2.0}
      ],
      "speaker": "SPEAKER_00"
    }
  ],
  "language": "es"
}
```

### TXT (simple)
```
Hola, ¬øc√≥mo est√°s?
Muy bien, gracias.
```

### SRT (subt√≠tulos)
```
1
00:00:00,500 --> 00:00:03,200
Hola, ¬øc√≥mo est√°s?

2
00:00:03,500 --> 00:00:06,800
Muy bien, gracias.
```

### VTT (WebVTT)
```
WEBVTT

00:00:00.500 --> 00:00:03.200
Hola, ¬øc√≥mo est√°s?

00:00:03.500 --> 00:00:06.800
Muy bien, gracias.
```

## üîß Uso como Biblioteca Python

Tambi√©n puedes importar y usar la funci√≥n directamente:

```python
from whisperx_script import transcribe_audio

result = transcribe_audio(
    audio_path="audio.mp3",
    output_dir="./output",
    model_name="large-v3",
    language="es",
    enable_diarization=True,
    hf_token="YOUR_HF_TOKEN"
)

# Acceder a los segmentos
for segment in result["segments"]:
    print(f"[{segment['start']:.2f}s] {segment['text']}")
```

## üêõ Soluci√≥n de Problemas

### Error: CUDA out of memory
```bash
# Reduce el batch_size
python whisperx_script.py audio.mp3 --batch-size 8

# O usa un modelo m√°s peque√±o
python whisperx_script.py audio.mp3 --model small
```

### Error: HF token inv√°lido
```bash
# 1. Crea token en: https://huggingface.co/settings/tokens
# 2. Acepta el modelo: https://huggingface.co/pyannote/speaker-diarization-3.1
# 3. Usa el token:
python whisperx_script.py audio.mp3 --diarize --hf-token hf_xxxxxxxxxxxxx
```

### Error: Alineaci√≥n no disponible
```bash
# Algunos idiomas no tienen modelos de alineaci√≥n
# Usa --no-align para deshabilitar
python whisperx_script.py audio.mp3 --no-align
```

### Audio muy largo (>2 horas)
```bash
# Reduce batch_size y usa compute_type int8
python whisperx_script.py audio_largo.mp3 \
  --batch-size 4 \
  --compute-type int8
```

## üìà Rendimiento

En una **RTX 3060 (12GB VRAM)**:

- **Audio de 10 minutos**: ~30 segundos (sin diarizaci√≥n), ~60 segundos (con diarizaci√≥n)
- **Audio de 1 hora**: ~3-5 minutos (sin diarizaci√≥n), ~8-10 minutos (con diarizaci√≥n)
- **Modelo large-v3**: ~70x tiempo real con batch_size=16

## ü§ù Contribuir

Este script es parte del repositorio [ai-tools-ubuntu-setup](https://github.com/edgardozavala/ai-tools-ubuntu-setup).

Mejoras bienvenidas:
- [ ] Soporte para m√∫ltiples archivos en batch
- [ ] Interfaz web con Gradio/Streamlit
- [ ] Configuraci√≥n de filtros de ruido
- [ ] Export a m√°s formatos (CSV, Excel)
- [ ] Progress bar para archivos largos

## üìÑ Licencia

MIT License - Usa libremente

## üôè Cr√©ditos

- [WhisperX](https://github.com/m-bain/whisperX) por Max Bain
- [OpenAI Whisper](https://github.com/openai/whisper) por OpenAI
- [Pyannote Audio](https://github.com/pyannote/pyannote-audio) para diarizaci√≥n

---

**‚≠ê Si te sirvi√≥ este script, dale una estrella al repo!**
